# 경사 하강법

## 확률적 경사 하강법

<img src = "https://drive.google.com/uc?id=1gd2HfgvBYXkx3BaOh_n-cmBvO5o3FF6w">
 <br> <br>
- 확률적 : 훈련세트에서 랜덤하게 하나의 샘플을 고르는 것 <br>
- 경사 하강 : 조금씩, 그러나 가장 가파른 경사를 따라 원하는 지점에 도달하는 것이 목표 <br>
=> **각 훈련 세트에서 랜덤하게 하나의 샘플을 골라 가파른 경사를 조금씩 내려가는 모델** <br><br>
- 사진의 빨간 점까지 내려오지 못하면 훈련세트에 모든 샘플을 다시 채워 넣은 후 다시 랜덤하게 하나의 샘플을 선택해 이어서 경사를 내려감
- 에포크 : 훈련 세트를 한 번 모두 사용하는 과정

## 미니배치 경사 하강법
- 무작위로 n개의 샘플을 선택하여 경사 하강법 수행

## 배치 경사 하강법
- 한 번 경사로를 따라 이동하기 위해 전체 샘플 사용
- 가장 안정적인 방법이나 컴퓨터 자원을 너무 많이 사용



# 손실 함수
- 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지 측정하는 기준
- 값이 작을수록 좋음
- 최솟값을 찾기 위해 경사 하강법 사용
- 연속적인(미분이 가능한) 데이터만 사용 가능

## 분류에서의 손실
- 정답을 못맞춤

## 로지스틱 손실 함수
- 이중 분류에서 사용
- 타깃 = 1 -> -log(예측함수)
- 타깃 = 0 -> log(1-예측함수)

## 크로스엔트로피 손실 함수
- 다중 분류에서 사용
<br><br>

## MSE (평균 제곱 오차)
- 회귀에서 사용하는 손실 함수
- 타깃에서 예측을 뺀 값을 제곱 후 모든 샘플에 평균한 값



# SGDClassifier

<img src = "https://drive.google.com/uc?id=1iuWRh1J0XSSP-s_QUrTFbLayfXwfSgB2" height=300>
<br> <br>

- 조기 종료 : 과대적합이 시작되기 전, 훈련 종료
  - 훈련 세트 점수는 에포크가 진행될수록 증가
  - 테스트 세트는 에포크가 증가할수록 어느순간 점수 감소

### hinge(힌지) 손실
- 서포트 백터 머신이라고도 불림
- SGDClassifier loss 매개변수의 기본값